name: caas

# ============================================================
# CAAS Platform - Unified Docker Compose
# Phase 1: Infrastructure Services (MongoDB, Kafka, Gateway)
# ============================================================

networks:
  caas-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  mongodb_primary_data:
  mongodb_secondary1_data:
  mongodb_secondary2_data:
  mongodb_config:
  redis_data:
  kafka1_data:
  kafka2_data:
  kafka3_data:
  zookeeper_data:

services:
  # ============================================
  # DATABASE SERVICES
  # ============================================
  
  mongodb-primary:
    image: mongo:7.0
    container_name: caas-mongodb-primary
    hostname: mongodb-primary
    entrypoint:
      - bash
      - -c
      - |
        mkdir -p /etc/mongo
        cp /tmp/mongo-keyfile /etc/mongo/mongo-keyfile
        chmod 400 /etc/mongo/mongo-keyfile
        chown 999:999 /etc/mongo/mongo-keyfile
        exec docker-entrypoint.sh mongod --replSet caas-rs --bind_ip_all --keyFile /etc/mongo/mongo-keyfile
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER:-caas_admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-caas_secret_2026}
    ports:
      - "27017:27017"
    volumes:
      - mongodb_primary_data:/data/db
      - mongodb_config:/data/configdb
      - ./init/mongodb/mongo-keyfile:/tmp/mongo-keyfile:ro
    networks:
      caas-network:
        ipv4_address: 172.28.1.1
    healthcheck:
      test: |
        mongosh --eval "
        try {
          db.adminCommand('ping');
          print('MongoDB is healthy');
        } catch(e) {
          print('MongoDB is not ready');
          quit(1);
        }
        " --quiet || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 40s
    restart: unless-stopped

  mongodb-secondary-1:
    image: mongo:7.0
    container_name: caas-mongodb-secondary-1
    hostname: mongodb-secondary-1
    entrypoint:
      - bash
      - -c
      - |
        mkdir -p /etc/mongo
        cp /tmp/mongo-keyfile /etc/mongo/mongo-keyfile
        chmod 400 /etc/mongo/mongo-keyfile
        chown 999:999 /etc/mongo/mongo-keyfile
        exec docker-entrypoint.sh mongod --replSet caas-rs --bind_ip_all --keyFile /etc/mongo/mongo-keyfile
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER:-caas_admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-caas_secret_2026}
    volumes:
      - mongodb_secondary1_data:/data/db
      - ./init/mongodb/mongo-keyfile:/tmp/mongo-keyfile:ro
    networks:
      caas-network:
        ipv4_address: 172.28.1.2
    depends_on:
      mongodb-primary:
        condition: service_healthy
    restart: unless-stopped

  mongodb-secondary-2:
    image: mongo:7.0
    container_name: caas-mongodb-secondary-2
    hostname: mongodb-secondary-2
    entrypoint:
      - bash
      - -c
      - |
        mkdir -p /etc/mongo
        cp /tmp/mongo-keyfile /etc/mongo/mongo-keyfile
        chmod 400 /etc/mongo/mongo-keyfile
        chown 999:999 /etc/mongo/mongo-keyfile
        exec docker-entrypoint.sh mongod --replSet caas-rs --bind_ip_all --keyFile /etc/mongo/mongo-keyfile
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER:-caas_admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-caas_secret_2026}
    volumes:
      - mongodb_secondary2_data:/data/db
      - ./init/mongodb/mongo-keyfile:/tmp/mongo-keyfile:ro
    networks:
      caas-network:
        ipv4_address: 172.28.1.3
    depends_on:
      mongodb-primary:
        condition: service_healthy
    restart: unless-stopped

  # MongoDB Initialization Service
  # Note: Initialization is now handled by init-system.ps1 script
  # mongodb-init:
  #   image: mongo:7.0
  #   container_name: caas-mongodb-init
  #   depends_on:
  #     mongodb-primary:
  #       condition: service_healthy
  #   networks:
  #     - caas-network
  #   environment:
  #     - MONGO_ROOT_USER=${MONGO_ROOT_USER:-caas_admin}
  #     - MONGO_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD:-caas_secret_2026}
  #     - MONGO_APP_PASSWORD=${MONGO_APP_PASSWORD:-caas_app_secret_2026}
  #   volumes:
  #     - ./init/mongodb/init-replica-and-collections.sh:/docker-entrypoint-initdb.d/init.sh:ro
  #   command: bash /docker-entrypoint-initdb.d/init.sh
  #   restart: "no"

  redis:
    image: redis:7-alpine
    container_name: caas-redis
    hostname: redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-caas_redis_2026}
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      caas-network:
        ipv4_address: 172.28.2.1
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-caas_redis_2026}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ============================================
  # MESSAGE QUEUE SERVICES
  # ============================================

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: caas-zookeeper
    hostname: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_4LW_COMMANDS_WHITELIST: "srvr,mntr,ruok"
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    networks:
      caas-network:
        ipv4_address: 172.28.3.1
    healthcheck:
      test: ["CMD-SHELL", "echo srvr | nc localhost 2181 | grep Mode"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  kafka-1:
    image: confluentinc/cp-kafka:7.5.0
    container_name: caas-kafka-1
    hostname: kafka-1
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - kafka1_data:/var/lib/kafka/data
    networks:
      caas-network:
        ipv4_address: 172.28.3.2
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    restart: unless-stopped

  kafka-2:
    image: confluentinc/cp-kafka:7.5.0
    container_name: caas-kafka-2
    hostname: kafka-2
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9096:9092"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:29092,PLAINTEXT_HOST://localhost:9096
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
    volumes:
      - kafka2_data:/var/lib/kafka/data
    networks:
      caas-network:
        ipv4_address: 172.28.3.3
    restart: unless-stopped

  kafka-3:
    image: confluentinc/cp-kafka:7.5.0
    container_name: caas-kafka-3
    hostname: kafka-3
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9094:9092"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:29092,PLAINTEXT_HOST://localhost:9094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
    volumes:
      - kafka3_data:/var/lib/kafka/data
    networks:
      caas-network:
        ipv4_address: 172.28.3.4
    restart: unless-stopped

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: caas-schema-registry
    hostname: schema-registry
    depends_on:
      kafka-1:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka-1:29092,kafka-2:29092,kafka-3:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      caas-network:
        ipv4_address: 172.28.3.5
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    restart: unless-stopped

  # Kafka Topics Initialization
  kafka-init:
    image: confluentinc/cp-kafka:7.5.0
    container_name: caas-kafka-init
    depends_on:
      kafka-1:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    networks:
      - caas-network
    command: >
      bash -c "
      echo 'Waiting for Kafka to be ready...';
      sleep 10;
      echo 'Creating Phase 1 topics...';
      kafka-topics --bootstrap-server kafka-1:29092 --create --if-not-exists --topic platform.events --partitions 3 --replication-factor 3 --config retention.ms=604800000 --config compression.type=snappy;
      kafka-topics --bootstrap-server kafka-1:29092 --create --if-not-exists --topic platform.audit --partitions 3 --replication-factor 3 --config retention.ms=2592000000 --config compression.type=snappy;
      kafka-topics --bootstrap-server kafka-1:29092 --create --if-not-exists --topic platform.notifications --partitions 3 --replication-factor 3 --config retention.ms=604800000;
      kafka-topics --bootstrap-server kafka-1:29092 --create --if-not-exists --topic internal.dlq --partitions 3 --replication-factor 3 --config retention.ms=2592000000;
      kafka-topics --bootstrap-server kafka-1:29092 --create --if-not-exists --topic auth.revocation.events --partitions 3 --replication-factor 3 --config retention.ms=2592000000;
      echo 'Kafka topics created successfully!';
      kafka-topics --bootstrap-server kafka-1:29092 --list;
      "
    restart: "no"

  # ============================================
  # API GATEWAY SERVICE
  # ============================================

  gateway:
    build:
      context: ./services/gateway
      dockerfile: Dockerfile
    container_name: caas-gateway
    hostname: gateway
    ports:
      - "3000:3000"
      - "3001:3001"
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - PORT=3000
      - METRICS_PORT=3001
      - MONGODB_URI=mongodb://${MONGO_ROOT_USER:-caas_admin}:${MONGO_ROOT_PASSWORD:-caas_secret_2026}@mongodb-primary:27017/caas_platform?authSource=admin&replicaSet=caas-rs
      - REDIS_URL=redis://:${REDIS_PASSWORD:-caas_redis_2026}@redis:6379/0
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-caas_redis_2026}
      - REDIS_DB=0
      - KAFKA_BROKERS=kafka-1:29092,kafka-2:29092,kafka-3:29092
      - JWT_SECRET=${JWT_SECRET:-change_this_in_production_please}
      - JWT_PRIVATE_KEY=${JWT_PRIVATE_KEY}
      - JWT_PUBLIC_KEY=${JWT_PUBLIC_KEY}
      - CORS_ORIGINS=${CORS_ORIGINS:-*}
    networks:
      caas-network:
        ipv4_address: 172.28.6.1
    depends_on:
      mongodb-primary:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "node", "-e", "const http = require('http'); http.get('http://127.0.0.1:3000/health', (res) => { process.exit(res.statusCode === 200 ? 0 : 1); }).on('error', () => process.exit(1));"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    command: >
      sh -c "
      mkdir -p /app/keys;
      if [ ! -z \"$JWT_PRIVATE_KEY\" ]; then echo \"$JWT_PRIVATE_KEY\" > /app/keys/private.pem; fi;
      if [ ! -z \"$JWT_PUBLIC_KEY\" ]; then echo \"$JWT_PUBLIC_KEY\" > /app/keys/public.pem; fi;
      node dist/main.js
      "

  # ============================================
  # DEVELOPMENT & MONITORING TOOLS
  # ============================================

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: caas-kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: caas-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:29092,kafka-2:29092,kafka-3:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
      DYNAMIC_CONFIG_ENABLED: "true"
    networks:
      - caas-network
    depends_on:
      - kafka-1
      - schema-registry
    restart: unless-stopped

  mongo-express:
    image: mongo-express:latest
    container_name: caas-mongo-express
    ports:
      - "8082:8081"
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_ROOT_USER:-caas_admin}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_ROOT_PASSWORD:-caas_secret_2026}
      ME_CONFIG_MONGODB_URL: mongodb://${MONGO_ROOT_USER:-caas_admin}:${MONGO_ROOT_PASSWORD:-caas_secret_2026}@mongodb-primary:27017,mongodb-secondary-1:27017,mongodb-secondary-2:27017/?replicaSet=caas-rs
      ME_CONFIG_BASICAUTH_USERNAME: ${MONGO_EXPRESS_USER:-admin}
      ME_CONFIG_BASICAUTH_PASSWORD: ${MONGO_EXPRESS_PASSWORD:-admin123}
    networks:
      - caas-network
    depends_on:
      mongodb-primary:
        condition: service_healthy
    restart: unless-stopped

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: caas-redis-commander
    environment:
      REDIS_HOSTS: local:redis:6379:0:${REDIS_PASSWORD:-caas_redis_2026}
    ports:
      - "8083:8081"
    networks:
      - caas-network
    depends_on:
      - redis
    restart: unless-stopped
